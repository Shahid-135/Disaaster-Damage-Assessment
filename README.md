# MGLTU-Net: Multi-Representation Graph Learning with Triplet Cross-Attentive Uncertainty-Guided Network
## Abstract  

Effective disaster response relies on timely and accurate damage assessment, yet existing methods struggle with ambiguous visual cues, heterogeneous damage patterns, and modality-specific uncertainties.  
In this work, we propose a principled framework that unifies **multi-representation graph learning**, **triplet cross-attention**, and **uncertainty-guided fusion** to address these challenges.  
Our approach introduces:  
1. A **Semantic Class-Aware Graph module** for semantically grounded relational reasoning.  
2. A **Multi-Scale Triplet Cross-Attention mechanism** to capture spatial dependencies across multiple dimensions.  
3. An **Uncertainty-Weighted Fusion strategy** that ensures robust integration even under compromised modalities.  

To support further research, we also introduce **DAMAGE**, a large-scale, manually annotated benchmark for complex damage assessment.


# ðŸ“‚ Project Structure: MGLTC-Net

The repository is organized as follows:

MGLTC-Net/
â”‚
â”œâ”€â”€ configs/ # YAML/JSON configs for experiments
â”‚ â”œâ”€â”€ default.yaml
â”‚ â””â”€â”€ crisismmd.yaml
â”‚
â”œâ”€â”€ data/ # Placeholder for datasets
â”‚ â”œâ”€â”€ DAMAGE/
â”‚ â””â”€â”€ CrisisMMD/
â”‚
â”œâ”€â”€ datasets/ # Dataset loaders
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ crisismmd.py
â”‚ â”œâ”€â”€ damage.py
â”‚ â””â”€â”€ transforms.py # Data augmentations
â”‚
â”œâ”€â”€ models/ # Model components
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ mgltc_net.py # Main model (MGLTC-Net)
â”‚ â”œâ”€â”€ semantic_graph.py # Semantic Class-Aware Graph module
â”‚ â”œâ”€â”€ triplet_attention.py # Multi-Scale Triplet Cross-Attention
â”‚ â””â”€â”€ fusion.py # Uncertainty-Weighted Fusion
â”‚
â”œâ”€â”€ utils/ # Helper functions
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ metrics.py # Evaluation metrics
â”‚ â”œâ”€â”€ losses.py # Custom loss functions
â”‚ â”œâ”€â”€ explainability.py # Explainability functions (Captum, SHAP)
â”‚ â””â”€â”€ visualization.py # Plots and result visualizations
â”‚
â”œâ”€â”€ experiments/ # Training and evaluation scripts
â”‚ â”œâ”€â”€ train.py # Main training loop
â”‚ â”œâ”€â”€ evaluate.py # Model evaluation
â”‚ â””â”€â”€ inference.py # Inference on new images
â”‚
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ requirements.md # Dependency documentation
â”œâ”€â”€ README.md # Project overview
â”œâ”€â”€ LICENSE # License file
â””â”€â”€ setup.py # Installable package (optional)

##Methodology

We propose a **multi-representation framework** for disaster damage severity classification that integrates **semantic graph reasoning, multi-scale visual attention, cross-modal alignment, uncertainty-guided fusion, and explainable features**.

---

## 1. Semantic Class-Aware Graph Adjacency Refinement (SCAR)

- Construct a **class-aware graph** using cosine similarity between pooled class prototypes.  
- Refine adjacency by **reinforcing intra-class edges** and attenuating inter-class ones.  
- Apply **GraphSAGE** for message passing to capture context-aware structural dependencies.  
- Produces **discriminative, semantically smooth embeddings** useful for fine-grained classification.

---

## 2. Feature Extraction

We adopt the **Swin Transformer** backbone to extract:

- **Global representation**: pooled feature vector `x_i âˆˆ â„^F`.  
- **Local representation**: patch-level features `H_i âˆˆ â„^(P Ã— F)`.

These serve as inputs for **graph modeling** and **attention modules**.

---

## 3. Multi-Scale Triplet Cross-Attention (MSTCA)

MSTCA models dependencies along three complementary dimensions:

- **Channel Attention (CA):** highlights semantic feature importance.  
- **Height Attention (HA):** captures vertical spatial dependencies.  
- **Width Attention (WA):** captures horizontal spatial dependencies.  

The outputs are fused via **adaptive softmax weighting** with global context modulation.  
A **cross-dimensional self-attention** refines the joint representation, enhancing robustness to visual ambiguity.

---

## 4. Cross-Modal Graph Refinement (CMGR)

- Project visual embeddings into graph space.  
- Use **visual embeddings as queries** in a multi-head attention mechanism over graph embeddings.  
- Fuse refined and original features via a **learnable gating mechanism**.  
- Result: **visually grounded graph features** that bridge semantic reasoning with visual cues.

---

## 5. Uncertainty-Weighted Fusion (UWF)

- Map both **graph** and **visual** features into a shared latent space.  
- Estimate **epistemic uncertainty** via *Monte Carlo dropout*.  
- Compute **adaptive fusion weights**: modalities with lower uncertainty receive higher weights.  
- Ensures stable and reliable performance even when one modality is compromised.

---

## 6. Explainable Features

We enhance interpretability by incorporating:

- **Saliency maps**  
- **Occlusion sensitivity analysis**  
- **Gradient-based activations**  
- **Structural descriptors**

These explainable features provide **transparent justifications** for model predictions â€” critical for trust and adoption in disaster response.

---
## Requirements  

To set up the environment for **MGLTC-Net**, install the following dependencies:  

### Core Dependencies  
- **torch>=2.0.0** â€“ Deep learning framework for model training and inference  
- **torchvision>=0.15.0** â€“ Computer vision utilities and datasets  
- **timm>=0.9.0** â€“ Access to advanced backbones (e.g., Swin Transformer, ViT)  
- **transformers>=4.30.0** â€“ Pretrained language/vision models from HuggingFace  
- **pytorch-lightning>=2.0.0** â€“ High-level training loop abstraction (optional but recommended)  

### Scientific & Utility Libraries  
- **numpy>=1.23.0** â€“ Numerical computations  
- **scipy>=1.10.0** â€“ Scientific computing utilities  
- **scikit-learn>=1.2.0** â€“ Metrics, preprocessing, and ML utilities  
- **pandas>=2.0.0** â€“ Data manipulation and analysis  
- **tqdm>=4.65.0** â€“ Progress bar for training and evaluation  

### Graph Learning  
- **spektral>=1.3.0** â€“ Graph neural network library (core for our relational reasoning)  
- **einops>=0.6.0** â€“ Flexible tensor operations for attention mechanisms  
- **torchmetrics>=0.11.0** â€“ Standardized evaluation metrics  

### Visualization & Augmentation  
- **matplotlib>=3.7.0** â€“ Visualization of results and plots  
- **seaborn>=0.12.2** â€“ Statistical data visualization  
- **opencv-python>=4.7.0** â€“ Image processing  
- **albumentations>=1.3.0** â€“ Advanced data augmentation  

### Explainability (Optional but Recommended)  
- **captum>=0.6.0** â€“ Model interpretability (saliency maps, occlusion, gradients)  
- **shap>=0.41.0** â€“ SHAP-based explainability methods  

---

### Installation  

Clone the repository and install requirements:  

```bash
git clone https://github.com/Shahid-135/MGLTC-Net.git
cd MGLTC-Net
pip install -r requirements.txt



